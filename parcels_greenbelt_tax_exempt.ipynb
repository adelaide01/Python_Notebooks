{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (61,69,71) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (92) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (63,107) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (88,89,92,107) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (90) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (97) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (59,69,93) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (107) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (8,71) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (91,97) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (63,75) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (63,91,99) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (63,92,97) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (61,97) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (60,92,107) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (59,63,70,97) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (59,69) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (100) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (63,65,92,98,107) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/46950173/python-looping-through-directory-and-saving-each-file-using-filename-as-data-fr\n",
    "\n",
    "root = '/Volumes/ACHEN/NAL/NAL_all_counties_2020/2_NAL_csv_versions/smallest-group'\n",
    "temp = {}\n",
    "for file in os.listdir(root):\n",
    "    if file.endswith(\".csv\"):\n",
    "        name = os.path.splitext(file)[0]\n",
    "        temp[name] = pd.read_csv(os.path.join(root, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NAL11F202001', 'NAL12F202001', 'NAL13F202001', 'NAL14F202001', 'NAL17F202001', 'NAL22F202002VAB', 'NAL24F202003', 'NAL25F202001', 'NAL28F202002VAB', 'NAL29F202001', 'NAL30F202001', 'NAL31F202002VAB', 'NAL32F202002VAB', 'NAL33F202002', 'NAL34F202001', 'NAL35F202001', 'NAL36F202001', 'NAL38F202001', 'NAL40F202001', 'NAL41F202001', 'NAL42F202003VAB', 'NAL43F202001', 'NAL44F202001', 'NAL47F202001', 'NAL48F202001', 'NAL49F202001', 'NAL50F202001', 'NAL53F202002', 'NAL54F202001', 'NAL55F202001', 'NAL56F202003VAB', 'NAL57F202002VAB', 'NAL64F202002VAB', 'NAL70F202001', 'NAL71F202002VAB', 'NAL72F202002VAB', 'NAL73F202001', 'NAL75F202001', 'NAL76F202002VAB', 'NAL77F202002VAB']\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/28669482/appending-pandas-dataframes-generated-in-a-for-loop\n",
    "# create a list of all the dataframe names in the batch \n",
    "df_list = []\n",
    "\n",
    "for key in temp.keys():\n",
    "    df_list.append(key)\n",
    "\n",
    "print(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for loop to go through all the dataframes\n",
    "# NAL11F202001 = pd.DataFrame.from_dict(temp['NAL11F202001'])\n",
    "# this is not my ideal method but I couldn't get the original one to work\n",
    "\n",
    "# batch1_counties = ['Alachua','Baker', 'Bay', 'Bradford', 'Calhoun', 'Columbia', 'DeSoto', 'Dixie', 'Flagler', 'Franklin', 'Gadsden', 'Gilchrist', 'Glades', 'Gulf', 'Hamilton', 'Hardee', 'Hendry', 'Highlands', 'Holmes', 'Indian River', 'Jackson', 'Jefferson', 'Lafayette', 'Leon', 'Levy', 'Liberty', 'Madison', 'Martin', 'Monroe', 'Nassau', 'Okaloosa', 'Okeechobee', 'Putnam', 'Sumter', 'Suwannee', 'Taylor', 'Union', 'Wakulla', 'Walton', 'Washington']\n",
    "\n",
    "# temp2 = {}\n",
    "\n",
    "# for county, b in zip(batch1_counties, df_list):\n",
    "#     temp2[county] = pd.DataFrame.from_dict(temp[df])\n",
    "\n",
    "Alachua = pd.DataFrame.from_dict(temp['NAL11F202001'])\n",
    "Baker = pd.DataFrame.from_dict(temp['NAL12F202001'])\n",
    "Bay = pd.DataFrame.from_dict(temp['NAL13F202001'])\n",
    "Bradford = pd.DataFrame.from_dict(temp['NAL14F202001'])\n",
    "Calhoun = pd.DataFrame.from_dict(temp['NAL17F202001'])\n",
    "Columbia = pd.DataFrame.from_dict(temp['NAL22F202002VAB'])\n",
    "DeSoto = pd.DataFrame.from_dict(temp['NAL24F202003'])\n",
    "Dixie = pd.DataFrame.from_dict(temp['NAL25F202001'])\n",
    "Flagler = pd.DataFrame.from_dict(temp['NAL28F202002VAB'])\n",
    "Franklin = pd.DataFrame.from_dict(temp['NAL29F202001'])\n",
    "Gadsden = pd.DataFrame.from_dict(temp['NAL30F202001'])\n",
    "Gilchrist = pd.DataFrame.from_dict(temp['NAL31F202002VAB'])\n",
    "Glades = pd.DataFrame.from_dict(temp['NAL32F202002VAB'])\n",
    "Gulf = pd.DataFrame.from_dict(temp['NAL33F202002'])\n",
    "Hamilton = pd.DataFrame.from_dict(temp['NAL34F202001'])\n",
    "Hardee = pd.DataFrame.from_dict(temp['NAL35F202001'])\n",
    "Hendry = pd.DataFrame.from_dict(temp['NAL36F202001'])\n",
    "Highlands = pd.DataFrame.from_dict(temp['NAL38F202001'])\n",
    "Holmes = pd.DataFrame.from_dict(temp['NAL40F202001'])\n",
    "IndianRiver = pd.DataFrame.from_dict(temp['NAL41F202001'])\n",
    "Jackson = pd.DataFrame.from_dict(temp['NAL42F202003VAB'])\n",
    "Jefferson = pd.DataFrame.from_dict(temp['NAL43F202001'])\n",
    "Lafayette = pd.DataFrame.from_dict(temp['NAL44F202001'])\n",
    "Leon = pd.DataFrame.from_dict(temp['NAL47F202001'])\n",
    "Levy = pd.DataFrame.from_dict(temp['NAL48F202001'])\n",
    "Liberty = pd.DataFrame.from_dict(temp['NAL49F202001'])\n",
    "Madison = pd.DataFrame.from_dict(temp['NAL50F202001'])\n",
    "Martin = pd.DataFrame.from_dict(temp['NAL53F202002'])\n",
    "Monroe = pd.DataFrame.from_dict(temp['NAL54F202001'])\n",
    "Nassau = pd.DataFrame.from_dict(temp['NAL55F202001'])\n",
    "Okaloosa = pd.DataFrame.from_dict(temp['NAL56F202003VAB'])\n",
    "Okeechobee = pd.DataFrame.from_dict(temp['NAL57F202002VAB'])\n",
    "Putnam = pd.DataFrame.from_dict(temp['NAL64F202002VAB'])\n",
    "Sumter = pd.DataFrame.from_dict(temp['NAL70F202001'])\n",
    "Suwannee = pd.DataFrame.from_dict(temp['NAL71F202002VAB'])\n",
    "Taylor = pd.DataFrame.from_dict(temp['NAL72F202002VAB'])\n",
    "Union = pd.DataFrame.from_dict(temp['NAL73F202001'])\n",
    "Wakulla = pd.DataFrame.from_dict(temp['NAL75F202001'])\n",
    "Walton = pd.DataFrame.from_dict(temp['NAL76F202002VAB'])\n",
    "Washington = pd.DataFrame.from_dict(temp['NAL77F202002VAB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dataframe with column names\n",
    "# names = ['CO_NO','PARCEL_ID','FILE_T','ASMNT_YR','BAS_STRT','ATV_STRT','GRP_NO','DOR_UC','PA_UC','SPASS_CD','JV','JV_CHNG','JV_CHNG_CD','AV_SD','AV_NSD','TV_SD','TV_NSD','JV_HMSTD','AV_HMSTD','JV_NON_HMSTD_RESD','AV_NON_HMSTD_RESD','JV_RESD_NON_RESD','AV_RESD_NON_RESD','JV_CLASS_USE','AV_CLASS_USE','JV_H2O_RECHRGE','AV_H2O_RECHRGE','JV_CONSRV_LND','AV_CONSRV_LND','JV_HIST_COM_PROP','AV_HIST_COM_PROP','JV_HIST_SIGNF','AV_HIST_SIGNF','JV_WRKNG_WTRFNT','AV_WRKNG_WTRFNT','NCONST_VAL','DEL_VAL','PAR_SPLT','DISTR_CD','DISTR_YR','LND_VAL','LND_UNTS_CD','NO_LND_UNTS','LND_SQFOOT','DT_LAST_INSPT','IMP_QUAL','CONST_CLASS','EFF_YR_BLT','ACT_YR_BLT','TOT_LVG_AREA','NO_BULDNG','NO_RES_UNTS','SPEC_FEAT_VAL','MULTI_PAR_SAL1','QUAL_CD1','VI_CD1','SALE_PRC1','SALE_YR1','SALE_MO1','OR_BOOK1','OR_PAGE1','CLERK_NO1','SAL_CHNG_CD1','MULTI_PAR_SAL2','QUAL_CD2','VI_CD2','SALE_PRC2','SALE_YR2','SALE_MO2','OR_BOOK2','OR_PAGE2','CLERK_NO2','SAL_CHNG_CD2','OWN_NAME','OWN_ADDR1','OWN_ADDR2','OWN_CITY','OWN_STATE','OWN_ZIPCD','OWN_STATE_DOM','FIDU_NAME','FIDU_ADDR1','FIDU_ADDR2','FIDU_CITY','FIDU_STATE','FIDU_ZIPCD','FIDU_CD','S_LEGAL','APP_STAT','CO_APP_STAT','MKT_AR','NBRHD_CD','PUBLIC_LND','TAX_AUTH_CD','TWN','RNG','SEC','CENSUS_BK','PHY_ADDR1','PHY_ADDR2','PHY_CITY','PHY_ZIPCD','ALT_KEY','ASS_TRNSFR_FG','PREV_HMSTD_OWN','ASS_DIF_TRNS','CONO_PRV_HM','PARCEL_ID_PRV_HMSTD','YR_VAL_TRNSF','EXMPT_01','EXMPT_02','EXMPT_03','EXMPT_04','EXMPT_05','EXMPT_06','EXMPT_07','EXMPT_08','EXMPT_09','EXMPT_10','EXMPT_11','EXMPT_12','EXMPT_13','EXMPT_14','EXMPT_15','EXMPT_16','EXMPT_17','EXMPT_18','EXMPT_19','EXMPT_20','EXMPT_21','EXMPT_22','EXMPT_23','EXMPT_24','EXMPT_25','EXMPT_26','EXMPT_27','EXMPT_28','EXMPT_29','EXMPT_30','EXMPT_31','EXMPT_32','EXMPT_33','EXMPT_34','EXMPT_35','EXMPT_36','EXMPT_37','EXMPT_38','EXMPT_39','EXMPT_40','EXMPT_41','EXMPT_80','EXMPT_81','EXMPT_82','SEQ_NO','RS_ID','MP_ID','STATE_PAR_ID','SPC_CIR_CD','SPC_CIR_YR','SPC_CIR_TXT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can merge multiple dataframes together as long as the column names are the same\n",
    "# merged_df = pd.concat([df1, df2] axis=1)\n",
    "merged_df = pd.concat([Alachua,Baker,Bay,Bradford,Calhoun,Columbia,DeSoto,Dixie,Flagler,Franklin,Gadsden,Gilchrist,Glades,Gulf,Hamilton,Hardee,Hendry,Highlands,Holmes,IndianRiver,Jackson,Jefferson,Lafayette,Leon,Levy,Liberty,Madison,Martin,Monroe,Nassau,Okaloosa,Okeechobee,Putnam,Sumter,Suwannee,Taylor,Union,Wakulla,Walton,Washington],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO_NO</th>\n",
       "      <th>PARCEL_ID</th>\n",
       "      <th>FILE_T</th>\n",
       "      <th>ASMNT_YR</th>\n",
       "      <th>BAS_STRT</th>\n",
       "      <th>ATV_STRT</th>\n",
       "      <th>GRP_NO</th>\n",
       "      <th>DOR_UC</th>\n",
       "      <th>PA_UC</th>\n",
       "      <th>SPASS_CD</th>\n",
       "      <th>...</th>\n",
       "      <th>EXMPT_80</th>\n",
       "      <th>EXMPT_81</th>\n",
       "      <th>EXMPT_82</th>\n",
       "      <th>SEQ_NO</th>\n",
       "      <th>RS_ID</th>\n",
       "      <th>MP_ID</th>\n",
       "      <th>STATE_PAR_ID</th>\n",
       "      <th>SPC_CIR_CD</th>\n",
       "      <th>SPC_CIR_YR</th>\n",
       "      <th>SPC_CIR_TXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11000</th>\n",
       "      <td>11</td>\n",
       "      <td>03230-001-020</td>\n",
       "      <td>R</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11086</td>\n",
       "      <td>1EE5</td>\n",
       "      <td>00002754</td>\n",
       "      <td>C11-000-001-0068-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11001</th>\n",
       "      <td>11</td>\n",
       "      <td>03230-001-021</td>\n",
       "      <td>R</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11087</td>\n",
       "      <td>1EE5</td>\n",
       "      <td>00002755</td>\n",
       "      <td>C11-000-001-0069-3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11002</th>\n",
       "      <td>11</td>\n",
       "      <td>03230-001-022</td>\n",
       "      <td>R</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11088</td>\n",
       "      <td>1EE5</td>\n",
       "      <td>00002756</td>\n",
       "      <td>C11-000-001-0070-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11003</th>\n",
       "      <td>11</td>\n",
       "      <td>03230-001-023</td>\n",
       "      <td>R</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11089</td>\n",
       "      <td>1EE5</td>\n",
       "      <td>00002757</td>\n",
       "      <td>C11-000-001-0071-9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11004</th>\n",
       "      <td>11</td>\n",
       "      <td>03230-001-024</td>\n",
       "      <td>R</td>\n",
       "      <td>2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11090</td>\n",
       "      <td>1EE5</td>\n",
       "      <td>00002758</td>\n",
       "      <td>C11-000-001-0072-7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CO_NO      PARCEL_ID FILE_T  ASMNT_YR  BAS_STRT  ATV_STRT  GRP_NO  \\\n",
       "11000     11  03230-001-020      R      2020       4.0       8.0     5.0   \n",
       "11001     11  03230-001-021      R      2020       1.0       1.0     1.0   \n",
       "11002     11  03230-001-022      R      2020       1.0       1.0     1.0   \n",
       "11003     11  03230-001-023      R      2020       1.0       1.0     1.0   \n",
       "11004     11  03230-001-024      R      2020       4.0       8.0     5.0   \n",
       "\n",
       "       DOR_UC PA_UC  SPASS_CD  ...  EXMPT_80  EXMPT_81  EXMPT_82  SEQ_NO  \\\n",
       "11000       0     0       NaN  ...       NaN       NaN       NaN   11086   \n",
       "11001       1     0       NaN  ...       NaN       NaN       NaN   11087   \n",
       "11002       1     0       NaN  ...       NaN       NaN       NaN   11088   \n",
       "11003       1     0       NaN  ...       NaN       NaN       NaN   11089   \n",
       "11004       0     0       NaN  ...       NaN       NaN       NaN   11090   \n",
       "\n",
       "       RS_ID     MP_ID        STATE_PAR_ID  SPC_CIR_CD  SPC_CIR_YR  \\\n",
       "11000   1EE5  00002754  C11-000-001-0068-5         NaN         NaN   \n",
       "11001   1EE5  00002755  C11-000-001-0069-3         NaN         NaN   \n",
       "11002   1EE5  00002756  C11-000-001-0070-1         NaN         NaN   \n",
       "11003   1EE5  00002757  C11-000-001-0071-9         NaN         NaN   \n",
       "11004   1EE5  00002758  C11-000-001-0072-7         NaN         NaN   \n",
       "\n",
       "       SPC_CIR_TXT  \n",
       "11000          NaN  \n",
       "11001          NaN  \n",
       "11002          NaN  \n",
       "11003          NaN  \n",
       "11004          NaN  \n",
       "\n",
       "[5 rows x 160 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the fields are there\n",
    "merged_df[11000:11005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make a new dataframe with only the fields we want\n",
    "df2 = merged_df[['CO_NO','PARCEL_ID','MP_ID','STATE_PAR_ID','DOR_UC','JV','JV_CLASS_USE','AV_CLASS_USE','OWN_NAME','OWN_ADDR1','OWN_ADDR2','OWN_CITY','OWN_ZIPCD','OWN_STATE_DOM','CENSUS_BK','PHY_ADDR1','PHY_ADDR2','PHY_CITY','PHY_ZIPCD','LND_UNTS_CD','NO_LND_UNTS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[df2['JV_CLASS_USE'].notna()] #in this case, keep rows where there is a number in filter the column JV_CLASS_USE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pandas/core/generic.py:5168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "# replace county two-digit codes with names\n",
    "# df.brand = df.brand.map( {'volvo':0 , 'bmw':1, 'audi':2} )\n",
    "\n",
    "df3.CO_NO = df3.CO_NO.map({11: 'Alachua', 12: 'Baker', 13: 'Bay', 14: 'Bradford', 15: 'Brevard', 16: 'Broward', 17: 'Calhoun', 18: 'Charlotte', 19: 'Citrus', 20: 'Clay', 21: 'Collier', 22: 'Columbia', 23: 'Dade', 24: 'DeSoto', 25: 'Dixie', 26: 'Duval', 27: 'Escambia', 28: 'Flagler', 29: 'Franklin', 30: 'Gadsden', 31: 'Gilchrist', 32: 'Glades', 33: 'Gulf', 34: 'Hamilton', 35: 'Hardee', 36: 'Hendry', 37: 'Hernando', 38: 'Highlands', 39: 'Hillsborough', 40: 'Holmes', 41: 'IndianRiver', 42: 'Jackson', 43: 'Jefferson', 44: 'Lafayette', 45: 'Lake', 46: 'Lee', 47: 'Leon', 48: 'Levy', 49: 'Liberty', 50: 'Madison', 51: 'Manatee', 52: 'Marion', 53: 'Martin', 54: 'Monroe', 55: 'Nassau', 56: 'Okaloosa', 57: 'Okeechobee', 58: 'Orange', 59: 'Osceola', 60: 'PalmBeach', 61: 'Pasco', 62: 'Pinellas', 63: 'Polk', 64: 'Putnam', 67: 'SantaRosa', 68: 'Sarasota', 69: 'Seminole', 65: 'StJohns', 66: 'StLucie', 70: 'Sumter', 71: 'Suwannee', 72: 'Taylor', 73: 'Union', 74: 'Volusia', 75: 'Wakulla', 76: 'Walton', 77: 'Washington'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_county = df3.groupby('CO_NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for county, group in group_by_county:\n",
    "    group.to_csv('{}_agr_2020.csv'.format(county), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
